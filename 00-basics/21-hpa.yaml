# Horizontal Pod Autoscaling: For this to work, the metrics server must be installed in the cluster.
# This example will create a deployment with 2 replicas and a horizontal pod autoscaler that scales the deployment
# based on CPU utilization. The autoscaler will scale the deployment to a maximum of 10 replicas if the CPU utilization exceeds 80%.
# The deployment will be created in the "expense" namespace and will use the nginx image.

apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:perl
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: nginx-deployment-svc
spec:
  selector:
    app: nginx
  type: LoadBalancer
  ports:
    - protocol: TCP
      port: 80                  # Port exposed by the service
      targetPort: 80            # Port exposed by the container: This is the port on which the container is listening

---
apiVersion: autoscaling/v2beta2
kind: HorizontalPodAutoscaler
metadata:
  name: nginx-deployment-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: nginx-deployment
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 75